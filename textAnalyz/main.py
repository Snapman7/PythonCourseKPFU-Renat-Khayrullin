import os
import re
from collections import Counter


class TextAnalyzer:
    def __init__(self):
        self.text = ""
        self.encoding = "utf-8"

    def try_decode(self, file_path):
        """–ü–æ–ø—ã—Ç–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ —Ä–∞–∑–Ω—ã–º–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞–º–∏"""
        encodings = ['utf-8', 'cp1251', 'koi8-r', 'iso-8859-1', 'windows-1251']

        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as file:
                    content = file.read()
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —á–∏—Ç–∞–µ—Ç—Å—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ
                    if content.strip():
                        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π: {encoding}")
                        return content, encoding
            except (UnicodeDecodeError, UnicodeError):
                continue
            except Exception as e:
                continue

        return None, None

    def load_file(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –ø–æ–ø—ã—Ç–∫–æ–π —Ä–∞–∑–Ω—ã—Ö –∫–æ–¥–∏—Ä–æ–≤–æ–∫"""
        file_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É: ").strip()

        if not os.path.exists(file_path):
            print("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            return False

        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
            content, encoding = self.try_decode(file_path)

            if content is None:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞!")
                return False

            self.text = content
            self.encoding = encoding
            print("‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
            return False

    def load_file_manual(self):
        """–†—É—á–Ω–æ–π –≤—ã–±–æ—Ä –∫–æ–¥–∏—Ä–æ–≤–∫–∏"""
        file_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É: ").strip()

        if not os.path.exists(file_path):
            print("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            return False

        print("\nüìù –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏:")
        encodings = ['utf-8', 'cp1251', 'koi8-r', 'iso-8859-1', 'windows-1251']
        for i, encoding in enumerate(encodings, 1):
            print(f"{i}. {encoding}")

        try:
            choice = int(input("–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–¥–∏—Ä–æ–≤–∫—É (1-5): "))
            if 1 <= choice <= len(encodings):
                encoding = encodings[choice - 1]
            else:
                encoding = 'utf-8'
        except ValueError:
            encoding = 'utf-8'

        try:
            with open(file_path, 'r', encoding=encoding) as file:
                self.text = file.read()
                self.encoding = encoding
            print("‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
            return True
        except UnicodeDecodeError:
            print("‚ùå –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è! –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É.")
            return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
            return False

    def count_words(self):
        """–ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤"""
        words = re.findall(r'\b\w+\b', self.text)
        return len(words)

    def count_characters(self):
        """–ü–æ–¥—Å—á–µ—Ç —Å–∏–º–≤–æ–ª–æ–≤ (—Å –ø—Ä–æ–±–µ–ª–∞–º–∏ –∏ –±–µ–∑)"""
        with_spaces = len(self.text)
        without_spaces = len(self.text.replace(' ', '').replace('\n', '').replace('\t', ''))
        return with_spaces, without_spaces

    def count_sentences(self):
        """–ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π"""
        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ . ! ? –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç
        sentences = re.split(r'[.!?]+', self.text)
        sentences = [s.strip() for s in sentences if s.strip() and len(s.strip()) > 1]
        return len(sentences)

    def count_unique_words(self):
        """–ü–æ–¥—Å—á–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤"""
        words = re.findall(r'\b\w+\b', self.text.lower())
        return len(set(words))

    def top_frequent_words(self, n=10):
        """–¢–æ–ø-N —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤"""
        words = re.findall(r'\b\w+\b', self.text.lower())
        # –ò—Å–∫–ª—é—á–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ (–º–µ–Ω—å—à–µ 3 –±—É–∫–≤)
        words = [word for word in words if len(word) > 2]
        word_counts = Counter(words)
        return word_counts.most_common(n)

    def count_paragraphs(self):
        """–ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∞–±–∑–∞—Ü–µ–≤"""
        paragraphs = [p for p in self.text.split('\n\n') if p.strip()]
        return len(paragraphs)

    def analyze_text(self):
        """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not self.text:
            print("‚ùå –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª!")
            return None

        print("\nüîç –í–´–ü–û–õ–ù–Ø–ï–¢–°–Ø –ê–ù–ê–õ–ò–ó –¢–ï–ö–°–¢–ê...")

        total_words = self.count_words()
        chars_with_spaces, chars_without_spaces = self.count_characters()
        sentences = self.count_sentences()
        unique_words = self.count_unique_words()
        paragraphs = self.count_paragraphs()
        top_words = self.top_frequent_words(10)

        analysis = {
            'total_words': total_words,
            'characters_with_spaces': chars_with_spaces,
            'characters_without_spaces': chars_without_spaces,
            'sentences': sentences,
            'paragraphs': paragraphs,
            'unique_words': unique_words,
            'top_words': top_words,
            'word_length_avg': chars_without_spaces / total_words if total_words > 0 else 0,
            'sentence_length_avg': total_words / sentences if sentences > 0 else 0
        }

        return analysis

    def generate_report(self, analysis):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞"""
        if not analysis:
            return

        report = f"""üìä –û–¢–ß–ï–¢ –ê–ù–ê–õ–ò–ó–ê –¢–ï–ö–°–¢–ê
{'=' * 50}

üìù –û–°–ù–û–í–ù–´–ï –°–¢–ê–¢–ò–°–¢–ò–ö–ò:
‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: {analysis['total_words']:,}
‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ (—Å –ø—Ä–æ–±–µ–ª–∞–º–∏): {analysis['characters_with_spaces']:,}
‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ (–±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤): {analysis['characters_without_spaces']:,}
‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {analysis['sentences']:,}
‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–±–∑–∞—Ü–µ–≤: {analysis['paragraphs']:,}
‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {analysis['unique_words']:,}

üìà –ü–õ–û–¢–ù–û–°–¢–¨ –¢–ï–ö–°–¢–ê:
‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞: {analysis['word_length_avg']:.1f} —Å–∏–º–≤–æ–ª–æ–≤
‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {analysis['sentence_length_avg']:.1f} —Å–ª–æ–≤
‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {(analysis['unique_words'] / analysis['total_words'] * 100):.1f}%

üî• –¢–û–ü-10 –°–ê–ú–´–• –ß–ê–°–¢–û–¢–ù–´–• –°–õ–û–í:
"""

        for i, (word, count) in enumerate(analysis['top_words'], 1):
            frequency = (count / analysis['total_words']) * 100
            report += f"{i:2d}. '{word}': {count:,} —Ä–∞–∑ ({frequency:.2f}%)\n"

        report += f"\n{'=' * 50}"
        report += f"\nüìÖ –û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {self.get_timestamp()}"

        return report

    def get_timestamp(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –¥–∞—Ç—ã –∏ –≤—Ä–µ–º–µ–Ω–∏"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def save_report(self, report):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –≤ —Ñ–∞–π–ª"""
        if not report:
            return

        timestamp = self.get_timestamp().replace(':', '-').replace(' ', '_')
        output_file = f"text_analysis_report_{timestamp}.txt"

        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {output_file}")
            return output_file
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
            return None

    def show_menu(self):
        print("\n" + "=" * 50)
        print("üìñ –ê–ù–ê–õ–ò–ó–ê–¢–û–† –¢–ï–ö–°–¢–ê")
        print("=" * 50)
        print("1. üìÇ –ê–≤—Ç–æ–∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ (–∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏)")
        print("2. üîß –†—É—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ (–≤—ã–±–æ—Ä –∫–æ–¥–∏—Ä–æ–≤–∫–∏)")
        print("3. üîç –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç")
        print("4. üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç")
        print("5. üìä –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É")
        print("6. üìù –ü–æ–∫–∞–∑–∞—Ç—å –æ–±—Ä–∞–∑–µ—Ü —Ç–µ–∫—Å—Ç–∞")
        print("0. ‚ùå –í—ã—Ö–æ–¥")
        print("=" * 50)

    def display_statistics(self, analysis):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ –∫–æ–Ω—Å–æ–ª–∏"""
        if not analysis:
            return

        print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –¢–ï–ö–°–¢–ê:")
        print(f"‚Ä¢ üìù –°–ª–æ–≤: {analysis['total_words']:,}")
        print(f"‚Ä¢ üî§ –°–∏–º–≤–æ–ª–æ–≤ (—Å –ø—Ä–æ–±–µ–ª–∞–º–∏): {analysis['characters_with_spaces']:,}")
        print(f"‚Ä¢ üî° –°–∏–º–≤–æ–ª–æ–≤ (–±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤): {analysis['characters_without_spaces']:,}")
        print(f"‚Ä¢ üìÑ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {analysis['sentences']:,}")
        print(f"‚Ä¢ üìë –ê–±–∑–∞—Ü–µ–≤: {analysis['paragraphs']:,}")
        print(f"‚Ä¢ üéØ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {analysis['unique_words']:,}")

        print(f"\nüìà –ü–õ–û–¢–ù–û–°–¢–¨:")
        print(f"‚Ä¢ üìè –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞: {analysis['word_length_avg']:.1f} —Å–∏–º–≤.")
        print(f"‚Ä¢ üìê –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {analysis['sentence_length_avg']:.1f} —Å–ª–æ–≤")

        print("\nüî• –¢–û–ü-10 –°–õ–û–í:")
        for i, (word, count) in enumerate(analysis['top_words'], 1):
            percentage = (count / analysis['total_words']) * 100
            print(f"  {i:2d}. '{word}': {count:,} —Ä–∞–∑ ({percentage:.1f}%)")

    def show_text_sample(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –æ–±—Ä–∞–∑–µ—Ü —Ç–µ–∫—Å—Ç–∞"""
        if not self.text:
            print("‚ùå –¢–µ–∫—Å—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω!")
            return

        sample_length = min(500, len(self.text))
        sample = self.text[:sample_length]

        print(f"\nüìù –û–ë–†–ê–ó–ï–¶ –¢–ï–ö–°–¢–ê (–ø–µ—Ä–≤—ã–µ {sample_length} —Å–∏–º–≤–æ–ª–æ–≤):")
        print("=" * 50)
        print(sample)
        if len(self.text) > sample_length:
            print("... [—Ç–µ–∫—Å—Ç –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è]")
        print("=" * 50)

    def run(self):
        current_analysis = None

        while True:
            self.show_menu()
            choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ: ")

            if choice == '0':
                print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                break
            elif choice == '1':
                if self.load_file():
                    print(f"üìñ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: {len(self.text):,}")
            elif choice == '2':
                if self.load_file_manual():
                    print(f"üìñ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: {len(self.text):,}")
            elif choice == '3':
                current_analysis = self.analyze_text()
                if current_analysis:
                    self.display_statistics(current_analysis)
            elif choice == '4':
                if current_analysis:
                    report = self.generate_report(current_analysis)
                    self.save_report(report)
                else:
                    print("‚ùå –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞!")
            elif choice == '5':
                if current_analysis:
                    self.display_statistics(current_analysis)
                else:
                    print("‚ùå –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞!")
            elif choice == '6':
                self.show_text_sample()
            else:
                print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä!")

            input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")


if __name__ == "__main__":
    analyzer = TextAnalyzer()
    analyzer.run()